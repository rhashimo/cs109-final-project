{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import functools\n",
    "import pickle\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy import stats\n",
    "from math import pi\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a progressbar function\n",
    "def progressbar(n_step, n_total):\n",
    "    \"\"\"Prints self-updating progress bar to stdout to track for-loop progress\n",
    "    \n",
    "    There are entire 3rd-party libraries dedicated to custom progress-bars.\n",
    "    A simple function like this is often more than enough to get the job done.\n",
    "    \n",
    "    :param n_total: total number of expected for-loop iterations\n",
    "    :type n_total: int\n",
    "    :param n_step: current iteration number, starting at 0\n",
    "    :type n_step: int\n",
    "\n",
    "    .. example::\n",
    "    \n",
    "        for i in range(n_iterations):\n",
    "            progressbar(i, n_iterations)\n",
    "            \n",
    "    .. source:\n",
    "    \n",
    "        This function is a simplified version of code found here:\n",
    "        https://stackoverflow.com/questions/3160699/python-progress-bar/15860757#15860757\n",
    "    \"\"\"\n",
    "    n_step = n_step + 1\n",
    "    barlen = 50\n",
    "    progress = n_step / n_total\n",
    "    block = int(round(barlen * progress))\n",
    "    status = \"\"\n",
    "    if n_step == n_total:\n",
    "        status = \"Done...\\r\\n\\n\"\n",
    "    text = \"\\r [{0}] {1}/{2} {3}\".format(\n",
    "        \"=\" * block + \"-\" * (barlen - block),\n",
    "        n_step,\n",
    "        n_total,\n",
    "        status,\n",
    "    )\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common parameters for figures\n",
    "fig_params = {'legend.fontsize': 'large',\n",
    "              'figure.figsize': (10, 6),\n",
    "              'axes.labelsize': 'large',\n",
    "              'axes.titlesize':'x-large',\n",
    "              'xtick.labelsize':'large',\n",
    "              'ytick.labelsize':'large'}\n",
    "pylab.rcParams.update(fig_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the dataset for Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 146) (17770, 146) (17991, 145)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/df_fifa.csv')\n",
    "\n",
    "# filter 2020 and 5 clubs (this dataframe is going to be test set)\n",
    "select_clubs = ['FC Barcelona','FC Bayern München','Real Madrid','Paris Saint-Germain','Juventus','Manchester City','Liverpool']\n",
    "df_b_2020 = df[(df['year'] == 2020) & (df['club'].isin(select_clubs))]\n",
    "\n",
    "# filter everything from 2019 (this is going to be training set)\n",
    "df_b_2019 = df[df['year'] == 2019]\n",
    "\n",
    "# merge two dataframe\n",
    "df_b = pd.concat([df_b_2019, df_b_2020]).drop(['d_foot_left'], axis=1)\n",
    "print(df_b_2020.shape, df_b_2019.shape, df_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17991, 316)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies for nationality, work rate, foot\n",
    "df_b_nationality = pd.get_dummies(df_b[['nationality']], prefix='d_nationality')\n",
    "df_b_workrate = pd.get_dummies(df_b[['work_rate']], prefix='d_workrate')\n",
    "df_b_foot = pd.get_dummies(df_b[['preferred_foot']], prefix='d_foot')\n",
    "#df_b_league = pd.get_dummies(df_b[['league_name']], prefix='d_foot')\n",
    "#df_b_club = pd.get_dummies(df_b[['club']], prefix='d_foot')\n",
    "\n",
    "# concate them into df_b\n",
    "df_b = pd.concat([df_b, df_b_nationality, df_b_workrate, df_b_foot], axis=1)\n",
    "df_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns, imputation, and train-test divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17770, 301) (221, 301)\n"
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "drop_vars = ['sofifa_id','short_name','dob','nationality','work_rate','body_type','team_position','loaned_from',\n",
    "            'preferred_foot','joined','contract_valid_until','league_name','team_jersey_number','club']\n",
    "df_b_all = df_b.copy().drop(drop_vars, axis=1)\n",
    "\n",
    "\n",
    "# group target vars into 4 \n",
    "position15 = ['ST','CF','LW','GK','CAM','CB','CM','CDM','RW','LB','LM','RB','RM','RWB','LWB']\n",
    "position4 = ['FW','FW','FW','GK','MF','DF','MF','MF','FW','DF','MF','DF','MF','DF','DF']\n",
    "position_conversion = dict(zip(position15, position4))\n",
    "df_b_all['main_position'] = [position_conversion[x] for x in df_b_all['main_position']]\n",
    "df_b_all['main_position'] = LabelEncoder().fit_transform(df_b_all['main_position'])\n",
    "\n",
    "# impute zero values for fieldplayers and goalkeeping ability\n",
    "# this is because goalkeeping ability is not available for field players and vice versa\n",
    "impute_vars = ['ab_pace','ab_shooting','ab_passing','ab_dribbling','ab_defending','ab_physic','release_clause_eur']\n",
    "impute_vars = impute_vars + [x for x in df_b_all.columns if x.startswith('ab_gk')]\n",
    "for var in impute_vars:\n",
    "    df_b_all[var] = df_b_all[var].fillna(0)\n",
    "    \n",
    "# impute mean value for ab_mentality_conposure\n",
    "# Composure is a Player Attribute in FIFA that determines a player's the state or feeling of being calm and \n",
    "# controlling their frustration in matches frustration. (from FIFAplay)\n",
    "df_b_all['ab_mentality_composure'].fillna(df_b_all['ab_mentality_composure'].mean(), inplace=True)\n",
    "\n",
    "# select players in the following clubs as test set\n",
    "df_b_te = df_b_all[df_b_all['year'] == 2020].drop(['year'], axis=1)\n",
    "df_b_tr = df_b_all[df_b_all['year'] == 2019].drop(['year'], axis=1)\n",
    "print(df_b_tr.shape, df_b_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "X_tr = df_b_tr.drop(['main_position'], axis=1)\n",
    "X_te = df_b_te.drop(['main_position'], axis=1)\n",
    "y_tr = df_b_tr['main_position']\n",
    "y_te = df_b_te['main_position'].values\n",
    "\n",
    "# count # of observations by class\n",
    "# set the desired # of minority classes (up/down) at 15% of the majority class (stay)\n",
    "counter = y_tr.value_counts().to_dict()\n",
    "counter_new = {}\n",
    "for key in counter.keys():\n",
    "    if not key == 1:\n",
    "        counter_new[key] = max(int(counter[1] * 0.15), counter[key])\n",
    "\n",
    "# upsampling using SMOTE. \n",
    "oversample = SMOTE(sampling_strategy = counter_new)\n",
    "X_tr, y_tr = oversample.fit_resample(X_tr.values, y_tr.values)\n",
    "\n",
    "# standardization\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "X_tr_stan = scaler.transform(X_tr)\n",
    "X_te_stan = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tr_stan = np.concatenate((y_tr.reshape((len(y_tr), 1)),X_tr_stan), axis=1)\n",
    "pd.DataFrame(data=b_tr_stan).to_csv('data/b_tr_stan.csv', index=False)\n",
    "b_te_stan = np.concatenate((y_te.reshape((len(y_te), 1)),X_te_stan), axis=1)\n",
    "pd.DataFrame(data=b_te_stan).to_csv('data/b_te_stan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryuic\\Anaconda3\\envs\\cs109a\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3], y=[1 1 1 ... 3 0 3] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# calculate class weight\n",
    "class_weights = list(class_weight.compute_class_weight('balanced',np.unique(y_tr),y_tr))\n",
    "w_array = np.ones(y_tr.shape[0], dtype = 'float')\n",
    "for i in range(len(y_tr)):\n",
    "    w_array[i] = class_weights[int(y_tr[i])]\n",
    "w_array\n",
    "# set parameters\n",
    "param_space = {'min_child_weight': hp.loguniform('min_child_weight', np.log(1), np.log(10)),\n",
    "               'max_depth': hp.quniform('max_depth', 3, 9, 1),\n",
    "               'subsample': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "               'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 0.95, 0.05),\n",
    "               'gamma': hp.loguniform('gamma', np.log(1e-8), np.log(1.0)),\n",
    "               'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-8), np.log(1.0)),\n",
    "               'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-6), np.log(10.0))}\n",
    "\n",
    "# define score function\n",
    "def score(params):\n",
    "    xgb = XGBClassifier(random_state=81,\n",
    "                        objective='multi:softmax',\n",
    "                        min_child_weight=params['min_child_weight'],\n",
    "                        max_depth=int(params['max_depth']), \n",
    "                        subsample=params['subsample'], \n",
    "                        colsample_bytree=params['colsample_bytree'],\n",
    "                        gamma=params['gamma'], \n",
    "                        reg_alpha=params['reg_alpha'], \n",
    "                        reg_lambda=params['reg_lambda'],\n",
    "                        sample_weight=w_array)\n",
    "    scores = cross_validate(xgb, \n",
    "                            X=X_tr_stan, \n",
    "                            y=y_tr, \n",
    "                            cv=5, \n",
    "                            scoring='accuracy', \n",
    "                            n_jobs=-1)\n",
    "    return scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████▋                          | 44/100 [37:36<49:25, 52.96s/trial, best loss: 0.9439504783342713]"
     ]
    }
   ],
   "source": [
    "# run gridsearch and find best parameters\n",
    "max_evals = 100\n",
    "trials = Trials()\n",
    "history = []\n",
    "rstate = np.random.RandomState(81)\n",
    "best_params = fmin(score, param_space, algo=tpe.suggest, trials=trials, max_evals=max_evals, rstate=rstate)\n",
    "\n",
    "# refit with the best parameters\n",
    "xgb_best = XGBClassifier(random_state=81,\n",
    "                         objective='multi:softmax',\n",
    "                         min_child_weight=best_params['min_child_weight'],\n",
    "                         max_depth=int(best_params['max_depth']), \n",
    "                         subsample=best_params['subsample'], \n",
    "                         colsample_bytree=best_params['colsample_bytree'],\n",
    "                         gamma=best_params['gamma'], \n",
    "                         reg_alpha=best_params['reg_alpha'], \n",
    "                         reg_lambda=best_params['reg_lambda'])\n",
    "xgb_best.fit(X_tr_stan, y_tr, sample_weight=w_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
